2025-07-14 19:36:27,837 INFO    MainThread:288673 [wandb_setup.py:_flush():77] Current SDK version is 0.17.9
2025-07-14 19:36:27,838 INFO    MainThread:288673 [wandb_setup.py:_flush():77] Configure stats pid to 288673
2025-07-14 19:36:27,838 INFO    MainThread:288673 [wandb_setup.py:_flush():77] Loading settings from /home/liqifeng/.config/wandb/settings
2025-07-14 19:36:27,838 INFO    MainThread:288673 [wandb_setup.py:_flush():77] Loading settings from /data1/lqf/behavior_simulation1/catk/scripts/wandb/settings
2025-07-14 19:36:27,838 INFO    MainThread:288673 [wandb_setup.py:_flush():77] Loading settings from environment variables: {'mode': 'dryrun'}
2025-07-14 19:36:27,838 INFO    MainThread:288673 [wandb_setup.py:_flush():77] Applying setup settings: {'_disable_service': False}
2025-07-14 19:36:27,838 WARNING MainThread:288673 [wandb_setup.py:_flush():77] Could not find program at -m src.run
2025-07-14 19:36:27,838 INFO    MainThread:288673 [wandb_setup.py:_flush():77] Inferring run settings from compute environment: {'program_relpath': None, 'program': '-m src.run'}
2025-07-14 19:36:27,838 INFO    MainThread:288673 [wandb_init.py:_log_setup():524] Logging user logs to /data1/lqf/behavior_simulation1/catk/scripts/logs/pre_bc-debug/runs/2025-07-14_19-36-22/wandb/offline-run-20250714_193627-2x4l7mix/logs/debug.log
2025-07-14 19:36:27,838 INFO    MainThread:288673 [wandb_init.py:_log_setup():525] Logging internal logs to /data1/lqf/behavior_simulation1/catk/scripts/logs/pre_bc-debug/runs/2025-07-14_19-36-22/wandb/offline-run-20250714_193627-2x4l7mix/logs/debug-internal.log
2025-07-14 19:36:27,838 INFO    MainThread:288673 [wandb_init.py:init():608] calling init triggers
2025-07-14 19:36:27,838 INFO    MainThread:288673 [wandb_init.py:init():615] wandb.init called with sweep_config: {}
config: {}
2025-07-14 19:36:27,838 INFO    MainThread:288673 [wandb_init.py:init():658] starting backend
2025-07-14 19:36:27,838 INFO    MainThread:288673 [wandb_init.py:init():662] setting up manager
2025-07-14 19:36:27,841 INFO    MainThread:288673 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2025-07-14 19:36:27,853 INFO    MainThread:288673 [wandb_init.py:init():670] backend started and connected
2025-07-14 19:36:27,859 INFO    MainThread:288673 [wandb_init.py:init():768] updated telemetry
2025-07-14 19:36:27,863 INFO    MainThread:288673 [wandb_init.py:init():801] communicating run to backend with 90.0 second timeout
2025-07-14 19:36:27,866 INFO    MainThread:288673 [wandb_init.py:init():852] starting run threads in backend
2025-07-14 19:36:31,891 INFO    MainThread:288673 [wandb_run.py:_console_start():2465] atexit reg
2025-07-14 19:36:31,892 INFO    MainThread:288673 [wandb_run.py:_redirect():2311] redirect: wrap_raw
2025-07-14 19:36:31,892 INFO    MainThread:288673 [wandb_run.py:_redirect():2376] Wrapping output streams.
2025-07-14 19:36:31,892 INFO    MainThread:288673 [wandb_run.py:_redirect():2401] Redirects installed.
2025-07-14 19:36:31,893 INFO    MainThread:288673 [wandb_init.py:init():895] run started, returning control to user process
2025-07-14 19:36:31,893 INFO    MainThread:288673 [wandb_watch.py:watch():51] Watching
2025-07-14 19:36:31,985 INFO    MainThread:288673 [wandb_run.py:_config_callback():1392] config_cb None None {'model': {'_target_': 'src.smart.model.smart.SMART', 'model_config': {'lr': 0.0005, 'lr_warmup_steps': 0, 'lr_total_steps': '${trainer.max_epochs}', 'lr_min_ratio': 0.01, 'n_rollout_closed_val': 32, 'n_batch_wosac_metric': 10, 'n_vis_batch': 2, 'n_vis_scenario': 5, 'n_vis_rollout': 5, 'val_open_loop': True, 'val_closed_loop': True, 'token_processor': {'map_token_file': 'map_traj_token5.pkl', 'agent_token_file': 'agent_vocab_555_s2.pkl', 'map_token_sampling': {'num_k': 1, 'temp': 1.0}, 'agent_token_sampling': {'num_k': 1, 'temp': 1.0}}, 'validation_rollout_sampling': {'criterium': 'topk_prob', 'num_k': 5, 'temp': 1.0}, 'training_rollout_sampling': {'criterium': 'topk_prob', 'num_k': -1, 'temp': 1.0}, 'decoder': {'hidden_dim': 128, 'num_freq_bands': 64, 'num_heads': 8, 'head_dim': 16, 'dropout': 0.1, 'hist_drop_prob': 0.1, 'num_map_layers': 3, 'num_agent_layers': 6, 'pl2pl_radius': 10, 'pl2a_radius': 30, 'a2a_radius': 60, 'time_span': 30, 'num_historical_steps': 11, 'num_future_steps': 80, 'use_xy_reconstruction': True, 'xy_reconstruction_weight': 0.1, 'xy_reconstruction_config': {'use_temporal_attention': True, 'use_feature_fusion': True, 'attention_heads': 8, 'fusion_dropout': 0.1, 'loss_type': 'mse', 'weight_schedule': {'warmup_epochs': 5, 'decay_rate': 0.5, 'min_weight': 0.01}}}, 'wosac_submission': {'is_active': False, 'method_name': 'SMART-tiny-CLSFT', 'authors': ['Anonymous'], 'affiliation': 'YOUR_AFFILIATION', 'description': 'YOUR_DESCRIPTION', 'method_link': 'YOUR_METHOD_LINK', 'account_name': 'YOUR_ACCOUNT_NAME'}, 'training_loss': {'use_gt_raw': True, 'gt_thresh_scale_length': -1.0, 'label_smoothing': 0.1, 'rollout_as_gt': False}, 'finetune': False}}, 'model/params/total': 7001024, 'model/params/trainable': 7001024, 'model/params/non_trainable': 0, 'data': {'_target_': 'src.smart.datamodules.MultiDataModule', 'train_batch_size': 10, 'val_batch_size': 10, 'test_batch_size': 10, 'num_workers': 10, 'shuffle': True, 'pin_memory': True, 'persistent_workers': True, 'train_raw_dir': '${paths.cache_root}/training', 'val_raw_dir': '${paths.cache_root}/validation', 'val_tfrecords_splitted': '${paths.cache_root}/validation_tfrecords_splitted', 'test_raw_dir': '${paths.cache_root}/testing', 'train_max_num': 32}, 'trainer': {'_target_': 'lightning.pytorch.trainer.Trainer', 'default_root_dir': '${paths.output_dir}', 'limit_train_batches': 1.0, 'limit_val_batches': 0.1, 'limit_test_batches': 1.0, 'max_epochs': 64, 'accelerator': 'gpu', 'devices': -1, 'precision': '32-true', 'check_val_every_n_epoch': 1, 'deterministic': False, 'gradient_clip_val': 0.5, 'num_sanity_val_steps': 0, 'accumulate_grad_batches': 1, 'log_every_n_steps': 1, 'strategy': 'auto'}, 'callbacks': {'model_checkpoint': {'_target_': 'lightning.pytorch.callbacks.ModelCheckpoint', 'dirpath': '${paths.output_dir}/checkpoints', 'filename': 'epoch_{epoch:03d}', 'monitor': None, 'verbose': False, 'save_last': 'link', 'save_top_k': 1, 'mode': 'min', 'auto_insert_metric_name': False, 'save_weights_only': False, 'every_n_train_steps': None, 'train_time_interval': None, 'every_n_epochs': 1, 'save_on_train_epoch_end': None}, 'model_summary': {'_target_': 'lightning.pytorch.callbacks.RichModelSummary', 'max_depth': -1}, 'learning_rate_monitor': {'_target_': 'lightning.pytorch.callbacks.LearningRateMonitor', 'logging_interval': 'epoch'}}, 'extras': None, 'task_name': 'pre_bc-debug', 'ckpt_path': None, 'seed': 817, 'train_job_id': None}
2025-07-14 19:36:35,436 WARNING MsgRouterThr:288673 [router.py:message_loop():77] message_loop has been closed
